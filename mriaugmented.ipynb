{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4229472,"sourceType":"datasetVersion","datasetId":2492800}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, gc\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16, DenseNet121, MobileNet\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\nimport time\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:28:53.276512Z","iopub.execute_input":"2025-04-30T23:28:53.276842Z","iopub.status.idle":"2025-04-30T23:28:53.282678Z","shell.execute_reply.started":"2025-04-30T23:28:53.276818Z","shell.execute_reply":"2025-04-30T23:28:53.281758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Load pre-trained model ---\ndef get_feature_extractor(model_name, input_shape=(224, 224, 3)):\n    if model_name == \"VGG16\":\n        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n    elif model_name == \"DenseNet121\":\n        base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape)\n    elif model_name == \"MobileNetV1\":\n        base_model = MobileNet(weights='imagenet', include_top=False, input_shape=input_shape)\n    else:\n        raise ValueError(\"Invalid model name\")\n    return base_model\n\n# --- Load ảnh ---\ndef load_data(directory, batch_size=32, target_size=(224, 224)):\n    datagen = ImageDataGenerator(rescale=1./255)\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=target_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False\n    )\n    return generator\n    \n# --- Load dữ liệu ---\ndata_dir_train = \"/kaggle/input/augmented-alzheimer-mri-dataset/AugmentedAlzheimerDataset\"\ndata_dir_test  = \"/kaggle/input/augmented-alzheimer-mri-dataset/OriginalDataset\"\ntrain_generator = load_data(data_dir_train)  \ntest_generator = load_data(data_dir_test)   \nnum_classes = len(train_generator.class_indices)\n\n# --- Trích xuất đặc trưng --\ndef extract_features_and_labels(model, generator):\n    # Tạo mô hình trích xuất đặc trưng\n    feature_extractor = Model(inputs=model.input, outputs=GlobalAveragePooling2D()(model.output))\n    # Trích xuất đặc trưng từ ảnh\n    features = feature_extractor.predict(generator, verbose=1)\n    labels = generator.classes[generator.index_array]\n    return features, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:28:53.285889Z","iopub.execute_input":"2025-04-30T23:28:53.286131Z","iopub.status.idle":"2025-04-30T23:29:06.770957Z","shell.execute_reply.started":"2025-04-30T23:28:53.286110Z","shell.execute_reply":"2025-04-30T23:29:06.770300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = ImageDataGenerator(rescale=1./255)\n\ntrain_datagen = train_data.flow_from_directory(\n    directory = data_dir_train,  \n    target_size=(224, 224),\n    class_mode='categorical'\n)\n\n# Lấy danh sách lớp\nclass_names = list(train_datagen.class_indices.keys())  \nclass_counts = np.bincount(train_datagen.classes)\n\n# Vẽ biểu đồ cột\nplt.figure(figsize=(8, 6))\nsns.barplot(x=class_names, y=class_counts, palette='Blues')\n# Thêm nhãn và tiêu đề\nplt.xlabel(\"Lớp MRI\", fontsize=12)\nplt.ylabel(\"Số lượng mẫu\", fontsize=12)\nplt.title(\"Số lượng ảnh MRI tăng cường trong từng lớp\", fontsize=14)\n\nfor i, count in enumerate(class_counts):\n    plt.text(i, count + 5, str(count), ha='center', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:29:06.772021Z","iopub.execute_input":"2025-04-30T23:29:06.772260Z","iopub.status.idle":"2025-04-30T23:29:07.801468Z","shell.execute_reply.started":"2025-04-30T23:29:06.772239Z","shell.execute_reply":"2025-04-30T23:29:07.800659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = ImageDataGenerator(rescale=1./255)\n\ntest_datagen = test_data.flow_from_directory(\n    directory = data_dir_test,  # Thay bằng đường dẫn thư mục test\n    target_size=(224, 224),\n    class_mode='categorical'\n)\n\n# Lấy danh sách lớp\nclass_names_t = list(test_datagen.class_indices.keys())  \nclass_counts_t = np.bincount(test_datagen.classes)\n\n# Vẽ biểu đồ cột\nplt.figure(figsize=(8, 6))\nsns.barplot(x=class_names_t, y=class_counts_t, palette='Blues')\n# Thêm nhãn và tiêu đề\nplt.xlabel(\"Lớp MRI\", fontsize=12)\nplt.ylabel(\"Số lượng mẫu\", fontsize=12)\nplt.title(\"Số lượng ảnh MRI gốc trong từng lớp\", fontsize=14)\n\nfor i, count in enumerate(class_counts_t):\n    plt.text(i, count + 5, str(count), ha='center', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:29:07.802980Z","iopub.execute_input":"2025-04-30T23:29:07.803236Z","iopub.status.idle":"2025-04-30T23:29:08.175005Z","shell.execute_reply.started":"2025-04-30T23:29:07.803213Z","shell.execute_reply":"2025-04-30T23:29:08.174099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Build Neural Network (NN) ===\ndef build_nn_classifier(input_dim, num_classes):\n    model = Sequential([\n        Dense(1024, activation='relu', input_shape=(input_dim,)),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.2),\n        Dense(num_classes, activation='softmax')\n    ])\n\n    model.compile(optimizer=Adam(learning_rate=1e-4),\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n\ndef run_nn_classifier(X_train, y_train, X_test, y_test, input_dim, num_classes):\n    clf = build_nn_classifier(input_dim, num_classes)\n    clf.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.1)\n    loss, acc = clf.evaluate(X_test, y_test)\n    y_pred = np.argmax(clf.predict(X_test), axis=1)\n    return acc * 100, y_pred, clf\n\n\n# === LR ===\ndef run_lr_classifier(X_train, y_train, X_test, y_test):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    lr = LogisticRegression(max_iter=3000, solver='sag', multi_class='multinomial', C=5, n_jobs=-1,\n        random_state=42)\n    lr.fit(X_train_scaled, y_train)\n    y_pred = lr.predict(X_test_scaled)\n    acc = accuracy_score(y_test, y_pred)\n    return acc * 100, y_pred, lr, scaler\n\n# === RF ===\ndef run_rf_classifier(X_train, y_train, X_test, y_test):\n    rf = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)\n    rf.fit(X_train, y_train)\n    y_pred = rf.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    return acc * 100, y_pred, rf\n\n# === SVM ===\ndef run_svm_classifier(X_train, y_train, X_test, y_test):\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\n    svm = SVC(kernel='rbf', C=0.3, gamma='scale')   #C=0.1\n    svm.fit(X_train_scaled, y_train)\n    y_pred = svm.predict(X_test_scaled)\n    acc = accuracy_score(y_test, y_pred)\n    return acc * 100, y_pred, svm, scaler\n\n\n# --- Phân tích ---\ndef plot_confusion_matrix(y_true, y_pred, class_labels, title):\n    cm = confusion_matrix(y_true, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n    \n    fig, ax = plt.subplots(figsize=(8, 6))   #10,8\n    disp.plot(cmap=plt.cm.Blues, ax=ax)\n\n    for text in ax.texts:\n        text.set_fontsize(18)   #16\n\n    plt.xticks(rotation=45, ha='right', fontsize=14)  #10\n    plt.yticks(rotation=0, fontsize=14)  \n    \n    plt.title(title, fontsize=16)  #14\n    plt.tight_layout()  \n    plt.show()\n\n\ndef print_classification_metrics(y_true, y_pred, classifier_name, model_name):\n    print(f\"\\n Classification Report for {classifier_name} - {model_name}:\")\n    print(classification_report(y_true, y_pred))\n\n#def measure_inference_time(model, X_test, name=\"Model\"):\n#    start_time = time.time()\n#    _ = model.predict(X_test)\n#    duration = time.time() - start_time\n#    print(f\"⏱ Inference time for {name}: {duration:.4f} seconds\")\n\ndef plot_model_comparison(results):\n    classifiers = list(next(iter(results.values())).keys())\n    x = np.arange(len(results))\n    width = 0.2\n    plt.figure(figsize=(12, 6))\n    for i, clf in enumerate(classifiers):\n        accs = [results[model][clf] for model in results]\n        bars = plt.bar(x + i * width, accs, width=width, label=clf)\n\n        # Thêm nhãn giá trị accuracy trên đầu cột\n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2.0, height + 0.5, f'{height:.2f}%', \n                     ha='center', va='bottom', fontsize=10)\n        #plt.bar(x + i * width, accs, width=width, label=clf)\n    # Điều chỉnh lại vị trí legend để không bị đè lên biểu đồ\n    plt.xticks(x + width * (len(classifiers)-1)/2, results.keys())\n    plt.ylabel(\"Accuracy (%)\")\n    plt.title(\"So sánh hiệu suất các mô hình và phương pháp phân lớp\")\n    \n    # Di chuyển legend ra ngoài biểu đồ\n    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n\n    plt.tight_layout()  # Đảm bảo layout đẹp khi có legend ngoài\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:29:08.176317Z","iopub.execute_input":"2025-04-30T23:29:08.176585Z","iopub.status.idle":"2025-04-30T23:29:08.190628Z","shell.execute_reply.started":"2025-04-30T23:29:08.176563Z","shell.execute_reply":"2025-04-30T23:29:08.189814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- So sánh mô hình ---\nmodels_list = [\"VGG16\", \"DenseNet121\", \"MobileNetV1\"]\naccuracy_results = {}\n\nclass_labels = list(train_generator.class_indices.keys())\n\nfor model_name in models_list:\n    print(f\"\\n Processing pre-trained model: {model_name}\")\n    base_model = get_feature_extractor(model_name)\n\n    print(\" Extracting features...\")\n    X_train, y_train = extract_features_and_labels(base_model, train_generator)\n    X_test, y_test  = extract_features_and_labels(base_model, test_generator)\n    input_dim = X_train.shape[1]\n\n    print(\" Training MLP classifier...\")\n    acc_nn, y_pred_nn, nn_model = run_nn_classifier(X_train, y_train, X_test, y_test, input_dim, num_classes)\n    print(f\" MLP Accuracy: {acc_nn:.2f}%\")\n\n    print(\" Training Logistic Regression classifier...\")\n    acc_lr, y_pred_lr, lr_model, lr_scaler = run_lr_classifier(X_train, y_train, X_test, y_test)\n    print(f\" Logistic Regression Accuracy: {acc_lr:.2f}%\")\n    \n    print(\" Training Random Forest classifier...\")\n    acc_rf, y_pred_rf, rf_model = run_rf_classifier(X_train, y_train, X_test, y_test)\n    print(f\" Random Forest Accuracy: {acc_rf:.2f}%\")\n    \n    print(\" Training SVM classifier on extracted features...\")\n    acc_svm, y_pred_svm, svm_model, svm_scaler = run_svm_classifier(X_train, y_train, X_test, y_test)\n    print(f\" SVM classifier Accuracy: {acc_svm:.2f}%\")\n\n    # === Evaluation ===\n    print_classification_metrics(y_test, y_pred_nn, \"MLP\", model_name)\n    print_classification_metrics(y_test, y_pred_lr, \"Logistic Regression\", model_name)\n    print_classification_metrics(y_test, y_pred_rf, \"Random Forest\", model_name)\n    print_classification_metrics(y_test, y_pred_svm, \"SVM\", model_name)\n\n    plot_confusion_matrix(y_test, y_pred_nn, class_labels, f\"MLP - {model_name}\")\n    plot_confusion_matrix(y_test, y_pred_lr, class_labels, f\"LR - {model_name}\")\n    plot_confusion_matrix(y_test, y_pred_rf, class_labels, f\"RF - {model_name}\")\n    plot_confusion_matrix(y_test, y_pred_svm, class_labels, f\"SVM - {model_name}\")\n\n    #measure_inference_time(nn_model, X_test, name=f\"NN - {model_name}\")\n    #measure_inference_time(lr_model, lr_scaler.transform(X_test), name=f\"LR - {model_name}\")\n    #measure_inference_time(rf_model, X_test, name=f\"RF - {model_name}\")\n    #measure_inference_time(svm_model, svm_scaler.transform(X_test), name=f\"SVM - {model_name}\")\n\n    accuracy_results[model_name] = {\n        \"MLP\": acc_nn,\n        \"Logistic Regression\": acc_lr,\n        \"Random Forest\": acc_rf,\n        \"SVM\": acc_svm\n    }\n\n    # Lưu lại kết quả dự đoán để phân tích sau\n    if 'all_preds' not in globals():\n        all_preds = {}\n    all_preds[model_name] = {\n        \"MLP\": y_pred_nn,\n        \"LR\": y_pred_lr,\n        \"RF\": y_pred_rf,\n        \"SVM\": y_pred_svm,\n        \"y_test\": y_test\n    }\n\n\n    del base_model, X_train, X_test, y_train, y_test\n    tf.keras.backend.clear_session()\n    gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:29:08.191529Z","iopub.execute_input":"2025-04-30T23:29:08.191731Z","iopub.status.idle":"2025-04-30T23:36:26.534700Z","shell.execute_reply.started":"2025-04-30T23:29:08.191714Z","shell.execute_reply":"2025-04-30T23:36:26.534012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n Summary of Results:\")\nfor model_name, results in accuracy_results.items():\n    print(f\"\\n {model_name}:\")\n    for clf, acc in results.items():\n        print(f\"{clf}: {acc:.2f}%\")\nplot_model_comparison(accuracy_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:36:26.546359Z","iopub.execute_input":"2025-04-30T23:36:26.546596Z","iopub.status.idle":"2025-04-30T23:36:26.828388Z","shell.execute_reply.started":"2025-04-30T23:36:26.546577Z","shell.execute_reply":"2025-04-30T23:36:26.827654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nresults_df = pd.DataFrame(accuracy_results)\nresults_df = results_df.round(2)\n# In bảng kết quả accuracy\nprint(\"\\n Summary of Results:\")\nprint(results_df.to_string(index=True))  # Chuyển DataFrame thành bảng và in ra","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:36:26.829153Z","iopub.execute_input":"2025-04-30T23:36:26.829453Z","iopub.status.idle":"2025-04-30T23:36:26.836236Z","shell.execute_reply.started":"2025-04-30T23:36:26.829421Z","shell.execute_reply":"2025-04-30T23:36:26.835596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_misclassified_images(images, y_true, y_pred, title, class_labels, max_images=6):\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    misclassified_idx = np.where(y_true != y_pred)[0]\n    if len(misclassified_idx) == 0:\n        print(f\"No misclassified images for {title}\")\n        return\n\n    print(f\" Showing {min(len(misclassified_idx), max_images)} misclassified images for {title}\")\n    plt.figure(figsize=(10, 7))\n    for i, idx in enumerate(misclassified_idx[:max_images]):\n        image = images[idx]\n        label_true = class_labels[int(y_true[idx])]\n        label_pred = class_labels[int(y_pred[idx])]\n\n        # Đảm bảo ảnh có đúng 3 kênh\n        if image.ndim == 2:\n            image = np.stack((image,) * 3, axis=-1)\n        elif image.shape[-1] != 3:\n            image = image[..., :3]\n\n        image = np.clip(image, 0, 1)\n\n        plt.subplot(2, 3, i + 1)\n        plt.imshow(image)\n        plt.title(f\"True: {label_true}\\nPred: {label_pred}\", color='red')\n        plt.axis('off')\n\n    plt.suptitle(title, fontsize=14)\n    plt.subplots_adjust(hspace=0.4)  # tăng khoảng cách dọc giữa các hàng\n    plt.tight_layout(rect=[0, 0, 1, 0.95])  # chừa khoảng cho suptitle\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:36:26.836927Z","iopub.execute_input":"2025-04-30T23:36:26.837120Z","iopub.status.idle":"2025-04-30T23:36:26.852129Z","shell.execute_reply.started":"2025-04-30T23:36:26.837104Z","shell.execute_reply":"2025-04-30T23:36:26.851367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load lại đúng ảnh test để hiển thị\nprint(\"\\n Loading test images for visualization...\")\n# Load lại ảnh test theo đúng thứ tự\ntest_image_paths = test_generator.filepaths\nimage_array = []\nfor path in test_image_paths:\n    img = tf.keras.utils.load_img(path, color_mode='rgb', target_size=(224, 224))\n    img = tf.keras.utils.img_to_array(img)\n    img = img / 255.0\n    image_array.append(img)\nimage_array = np.array(image_array, dtype=np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:36:26.854206Z","iopub.execute_input":"2025-04-30T23:36:26.854447Z","iopub.status.idle":"2025-04-30T23:36:38.988145Z","shell.execute_reply.started":"2025-04-30T23:36:26.854428Z","shell.execute_reply":"2025-04-30T23:36:38.987383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n Displaying misclassified images for each model & classifier...\")\nfor model_name in all_preds:\n    y_test = all_preds[model_name][\"y_test\"]\n    for clf_name in [\"MLP\", \"LR\", \"RF\", \"SVM\"]:\n        y_pred = all_preds[model_name][clf_name]\n        show_misclassified_images(image_array, y_test, y_pred, f\"{clf_name} Misclassified - {model_name}\", class_labels)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:36:38.990110Z","iopub.execute_input":"2025-04-30T23:36:38.990412Z","iopub.status.idle":"2025-04-30T23:36:39.603199Z","shell.execute_reply.started":"2025-04-30T23:36:38.990389Z","shell.execute_reply":"2025-04-30T23:36:39.602148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df = pd.DataFrame(accuracy_results).T\nresults_df.to_csv(\"alzheimer_model_comparison.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T23:36:39.603612Z","iopub.status.idle":"2025-04-30T23:36:39.603858Z","shell.execute_reply":"2025-04-30T23:36:39.603759Z"}},"outputs":[],"execution_count":null}]}
